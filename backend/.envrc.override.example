#!/usr/bin/env bash
# Example .envrc.override file
# Copy this to .envrc.override and update with your actual values

# ============================================
# LLM CONFIGURATION
# ============================================

# Single API key for any provider
export LLM_API_KEY="your-api-key-here"

# Choose your models (provider auto-detected from prefix)
# OpenAI models: gpt-4o, gpt-4o-mini, gpt-3.5-turbo
# DeepSeek models: deepseek-chat, deepseek-coder
export LLM_MODEL_QUIZ_PARSER="gpt-4o"              # or "deepseek-chat" for DeepSeek
export LLM_MODEL_QUIZ_RENDERER="gpt-4o-mini"       
export LLM_MODEL_ANSWER_VALIDATOR="gpt-4o-mini"    
export LLM_MODEL_KNOWLEDGE_EXTRACTOR="gpt-4o"      

# Optional: Override base URL (auto-detected if not set)
# export LLM_BASE_URL="https://api.openai.com/v1"  # OpenAI
# export LLM_BASE_URL="https://api.deepseek.com"   # DeepSeek

# Optional: Organization ID for OpenAI
# export LLM_ORGANIZATION="your-org-id"

# Fine-tune model behavior
export LLM_TEMP_QUIZ_PARSER="0.7"
export LLM_MAX_TOKENS_QUIZ_PARSER="4000"

# ============================================
# EXAMPLE CONFIGURATIONS
# ============================================

# --- Example 1: All DeepSeek (Most cost-effective) ---
# export LLM_API_KEY="your-deepseek-api-key"
# export LLM_MODEL_QUIZ_PARSER="deepseek-chat"
# export LLM_MODEL_QUIZ_RENDERER="deepseek-chat"
# export LLM_MODEL_ANSWER_VALIDATOR="deepseek-chat"
# export LLM_MODEL_KNOWLEDGE_EXTRACTOR="deepseek-chat"

# --- Example 2: All OpenAI (Best quality) ---
# export LLM_API_KEY="your-openai-api-key"
# export LLM_MODEL_QUIZ_PARSER="gpt-4o"
# export LLM_MODEL_QUIZ_RENDERER="gpt-4o-mini"
# export LLM_MODEL_ANSWER_VALIDATOR="gpt-4o-mini"
# export LLM_MODEL_KNOWLEDGE_EXTRACTOR="gpt-4o"

# --- Example 3: Mixed providers (Requires separate API keys) ---
# Note: When mixing providers, you'll need to set different API keys
# This is an advanced use case and may require custom configuration